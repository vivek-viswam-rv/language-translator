{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgnEkaprXi6e"
      },
      "source": [
        "# Language translator: English to French\n",
        "\n",
        "Vivek Viswam R. V. <br>\n",
        "Rachel Messenger"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "R5CIbK63DVsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVQIQ8jbIKuz",
        "outputId": "29766a2f-18d4-4d8a-c07c-4494776d8c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m139.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "\n",
        "!python -m pip install torchmetrics\n",
        "!python -m spacy download fr_core_news_sm\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "from torchmetrics.text import BLEUScore\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants"
      ],
      "metadata": {
        "id": "mQWBise3DTw8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X5wz1uDTfey"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = \"/content/drive/MyDrive/language-translator\"\n",
        "EN_REL_PATH = \"dataset/europarl-v7.fr-en.en\"\n",
        "FR_REL_PATH = \"dataset/europarl-v7.fr-en.fr\"\n",
        "TRAIN_STATS_FILENAME = \"training_stats.pth\"\n",
        "\n",
        "EN_PATH = os.path.join(ROOT_PATH, EN_REL_PATH)\n",
        "FR_PATH = os.path.join(ROOT_PATH, FR_REL_PATH)\n",
        "TRAIN_STATS_PATH = os.path.join(ROOT_PATH, TRAIN_STATS_FILENAME)\n",
        "\n",
        "\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "MAX_SENT_LEN = 100\n",
        "MAX_SEQ_LEN = 102\n",
        "MAX_LINE_COUNT = 200000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Misc definitions"
      ],
      "metadata": {
        "id": "9TVzGB5NSxwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
        "spacy_en = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "3u1cDIvqSvrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function definitions"
      ],
      "metadata": {
        "id": "IOitEOMSDcr1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHHcEw8En1zH"
      },
      "outputs": [],
      "source": [
        "tokenize_fr = lambda text: [ text for tok in spacy_fr.tokenizer(text) if (text:=tok.text.strip()) ]\n",
        "tokenize_en = lambda text: [ text for tok in spacy_en.tokenizer(text) if (text:=tok.text.strip()) ]\n",
        "\n",
        "def load_datasets(en_path=EN_PATH, fr_path=FR_PATH):\n",
        "  with open(EN_PATH) as en_f, open(FR_PATH) as fr_f:\n",
        "    return fr_f.read(), en_f.read()\n",
        "\n",
        "def preprocess(fr_text, en_text, max_line_count=MAX_LINE_COUNT, max_sent_len=MAX_SENT_LEN):\n",
        "  fr_text_lines = fr_text.splitlines()[:max_line_count]\n",
        "  en_text_lines = en_text.splitlines()[:max_line_count]\n",
        "\n",
        "  selected_idx = []\n",
        "  final_fr_lines = []\n",
        "  final_en_lines = []\n",
        "\n",
        "  for idx in range(len(fr_text_lines)):\n",
        "    fr_line = fr_text_lines[idx]\n",
        "    en_line = en_text_lines[idx]\n",
        "\n",
        "    fr_line_len = len(tokenize_fr(fr_line))\n",
        "    en_line_len = len(tokenize_en(en_line))\n",
        "\n",
        "    if fr_line_len <= max_sent_len and en_line_len <= max_sent_len:\n",
        "      selected_idx.append(idx)\n",
        "      final_fr_lines.append(fr_line)\n",
        "      final_en_lines.append(en_line)\n",
        "\n",
        "  processed_fr_text = \"\\n\".join(final_fr_lines).strip().lower()\n",
        "  processed_en_text = \"\\n\".join(final_en_lines).strip().lower()\n",
        "\n",
        "  return processed_fr_text, processed_en_text\n",
        "\n",
        "def create_vocabulary(text, tokenizer, min_freq=2):\n",
        "  token_freq = Counter(tokenizer(text))\n",
        "\n",
        "  tokens = [ tok for tok, freq in token_freq.items() ]\n",
        "  tokens = [ START_TOKEN, END_TOKEN, PAD_TOKEN ] + tokens\n",
        "  tok2idx = { tok: idx for idx, tok in enumerate(tokens) }\n",
        "  idx2tok = { idx: tok for idx, tok in enumerate(tokens) }\n",
        "\n",
        "  return tok2idx, idx2tok\n",
        "\n",
        "def tensorify_dataset(processed_text, lang_tok2idx, tokenizer):\n",
        "  split_lines = processed_text.splitlines()\n",
        "  final_lines = []\n",
        "  for line in split_lines:\n",
        "    tokens = tokenizer(line)\n",
        "    tokens = [ START_TOKEN ] + tokens + [ END_TOKEN ]\n",
        "    padding_size = max(0, MAX_SEQ_LEN - len(tokens))\n",
        "    tokens += [ PAD_TOKEN ] * padding_size\n",
        "    tokens = [ lang_tok2idx[tok] for tok in tokens ]\n",
        "    final_lines.append(tokens)\n",
        "\n",
        "  return torch.tensor(final_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class definitions"
      ],
      "metadata": {
        "id": "DFol28NEDl3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LangDataset(Dataset):\n",
        "  def __init__(self, src, target):\n",
        "    self.src = src\n",
        "    self.target = target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.src[idx], self.target[idx]\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self,\n",
        "               emb_size,\n",
        "               src_voc_size,\n",
        "               target_voc_size,\n",
        "               src_pad_idx,\n",
        "               num_heads,\n",
        "               num_encoder_layers,\n",
        "               num_decoder_layers,\n",
        "               forward_expansion,\n",
        "               dropout,\n",
        "               device\n",
        "    ):\n",
        "\n",
        "    super(Transformer, self).__init__()\n",
        "    self.device = device\n",
        "    self.src_word_embedding = nn.Embedding(src_voc_size, emb_size)\n",
        "    self.src_position_embedding = nn.Embedding(MAX_SEQ_LEN, emb_size)\n",
        "    self.target_word_embedding = nn.Embedding(target_voc_size, emb_size)\n",
        "    self.target_position_embedding = nn.Embedding(MAX_SEQ_LEN, emb_size)\n",
        "    self.device = device\n",
        "    self.transformer = nn.Transformer(\n",
        "        emb_size,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout\n",
        "    )\n",
        "\n",
        "    self.fc_out = nn.Linear(emb_size, target_voc_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "\n",
        "  def make_src_mask(self, src):\n",
        "    src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "    return src_mask.to(self.device)\n",
        "\n",
        "  def make_trg_mask(self, trg):\n",
        "    trg_pad_mask = (trg.transpose(0, 1) == self.src_pad_idx)\n",
        "    return trg_pad_mask.to(self.device)\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "    src_seq_len, N = src.shape\n",
        "    trg_seq_len, N = trg.shape\n",
        "\n",
        "    src_positions = (\n",
        "        torch.arange(0, src_seq_len).unsqueeze(1).expand(src_seq_len, N).to(self.device)\n",
        "    )\n",
        "\n",
        "    trg_positions = (\n",
        "        torch.arange(0, trg_seq_len).unsqueeze(1).expand(trg_seq_len, N)\n",
        "        .to(self.device)\n",
        "    )\n",
        "\n",
        "    emb_src = self.dropout(\n",
        "        (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "    )\n",
        "\n",
        "    emb_trg = self.dropout(\n",
        "        (self.target_word_embedding(trg) + self.target_position_embedding(trg_positions))\n",
        "    )\n",
        "\n",
        "    src_padding_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_len).to(self.device)\n",
        "    trg_padding_mask = self.make_trg_mask(trg)\n",
        "\n",
        "\n",
        "    out = self.transformer(\n",
        "        emb_src,\n",
        "        emb_trg,\n",
        "        src_key_padding_mask=src_padding_mask,\n",
        "        tgt_mask=trg_mask,\n",
        "        tgt_key_padding_mask=trg_padding_mask\n",
        "    )\n",
        "\n",
        "    out = self.fc_out(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "Kpkl5o8q999f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading dataset and vocabularies"
      ],
      "metadata": {
        "id": "zq3_cbXODoEW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqMsi5lk6EKj"
      },
      "outputs": [],
      "source": [
        "raw_fr_text, raw_en_text = load_datasets()\n",
        "processed_fr, processed_en = preprocess(raw_fr_text, raw_en_text)\n",
        "\n",
        "fr_tok2idx, fr_idx2tok = create_vocabulary(processed_fr, tokenize_fr)\n",
        "en_tok2idx, en_idx2tok = create_vocabulary(processed_en, tokenize_en)\n",
        "\n",
        "tensorified_fr = tensorify_dataset(processed_fr, fr_tok2idx, tokenize_fr).to(device)\n",
        "tensorified_en = tensorify_dataset(processed_en, en_tok2idx, tokenize_en).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading saved model"
      ],
      "metadata": {
        "id": "8FIuTFX8bsEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_data = torch.load(TRAIN_STATS_PATH)\n",
        "model_state_dict = saved_data[\"model_state_dict\"]\n",
        "\n",
        "num_epochs = 100\n",
        "learning_rate = 3e-4\n",
        "batch_size = 512\n",
        "\n",
        "src_vocab_size = len(fr_tok2idx)\n",
        "trg_vocab_size = len(en_tok2idx)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = MAX_SEQ_LEN\n",
        "forward_expansion = 4 * embedding_size\n",
        "src_pad_idx = fr_tok2idx[PAD_TOKEN]\n",
        "\n",
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(model_state_dict)\n",
        "model.eval()\n",
        "\n",
        "full_dataset = LangDataset(tensorified_fr, tensorified_en)\n",
        "train_data, test_data = torch.utils.data.random_split(full_dataset, [0.9, 0.1])\n",
        "train_iter = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_iter = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "I_QrXRndbqk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "Zeg7Z1biDzm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "learning_rate = 3e-4\n",
        "batch_size = 512\n",
        "\n",
        "src_vocab_size = len(fr_tok2idx)\n",
        "trg_vocab_size = len(en_tok2idx)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = MAX_SEQ_LEN\n",
        "forward_expansion = 4 * embedding_size\n",
        "src_pad_idx = fr_tok2idx[PAD_TOKEN]\n",
        "\n",
        "\n",
        "full_dataset = LangDataset(tensorified_fr, tensorified_en)\n",
        "train_data, test_data = torch.utils.data.random_split(full_dataset, [0.9, 0.1])\n",
        "train_iter = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_iter = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    device\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "pad_idx = fr_tok2idx[PAD_TOKEN]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "loss_history = []\n",
        "acc_history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  batch_loss = []\n",
        "  batch_acc = []\n",
        "\n",
        "  for batch_idx, (inp_data, target) in enumerate(train_iter):\n",
        "    src = inp_data.to(device).T\n",
        "    target = target.to(device).T\n",
        "    target_input = target[:-1, :]\n",
        "    target_output = target[1:, :]\n",
        "\n",
        "    output = model(src, target_input)\n",
        "\n",
        "    pred = output.argmax(2)\n",
        "    mask = (target_output != pad_idx)\n",
        "    correct = (pred == target_output) & mask\n",
        "    accuracy = correct.sum() / mask.sum()\n",
        "    batch_acc.append(accuracy)\n",
        "\n",
        "    output = output.reshape(-1, output.shape[2])\n",
        "    target = target_output.reshape(-1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    batch_loss.append(loss.item())\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  avg_batch_acc = float(sum(batch_acc) / len(batch_acc))\n",
        "  avg_batch_loss = sum(batch_loss) / len(batch_loss)\n",
        "  acc_history.append(avg_batch_acc)\n",
        "  loss_history.append(avg_batch_loss)\n",
        "\n",
        "  torch.save({\n",
        "      \"loss_history\": loss_history,\n",
        "      \"acc_history\": acc_history,\n",
        "      \"epoch\": epoch,\n",
        "      \"datapoints\": MAX_LINE_COUNT,\n",
        "      \"model_state_dict\": model.state_dict(),\n",
        "      \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "      }, TRAIN_STATS_PATH)\n",
        "\n",
        "  print(f\"Epoch {epoch + 1} / {num_epochs} - loss: {avg_batch_loss:.4f} - accuracy: {avg_batch_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osEUO2pBL5Id",
        "outputId": "7b749cb7-0200-48b4-cefd-68870ff34c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 100 - loss: 5.1525 - accuracy: 23.84%\n",
            "Epoch 2 / 100 - loss: 3.9611 - accuracy: 35.30%\n",
            "Epoch 3 / 100 - loss: 3.3871 - accuracy: 41.71%\n",
            "Epoch 4 / 100 - loss: 2.9753 - accuracy: 46.60%\n",
            "Epoch 5 / 100 - loss: 2.6873 - accuracy: 49.94%\n",
            "Epoch 6 / 100 - loss: 2.4804 - accuracy: 52.35%\n",
            "Epoch 7 / 100 - loss: 2.3216 - accuracy: 54.19%\n",
            "Epoch 8 / 100 - loss: 2.1964 - accuracy: 55.65%\n",
            "Epoch 9 / 100 - loss: 2.0909 - accuracy: 56.92%\n",
            "Epoch 10 / 100 - loss: 2.0012 - accuracy: 58.08%\n",
            "Epoch 11 / 100 - loss: 1.9243 - accuracy: 59.06%\n",
            "Epoch 12 / 100 - loss: 1.8562 - accuracy: 59.99%\n",
            "Epoch 13 / 100 - loss: 1.7966 - accuracy: 60.80%\n",
            "Epoch 14 / 100 - loss: 1.7432 - accuracy: 61.52%\n",
            "Epoch 15 / 100 - loss: 1.6950 - accuracy: 62.18%\n",
            "Epoch 16 / 100 - loss: 1.6502 - accuracy: 62.81%\n",
            "Epoch 17 / 100 - loss: 1.6099 - accuracy: 63.41%\n",
            "Epoch 18 / 100 - loss: 1.5732 - accuracy: 63.91%\n",
            "Epoch 19 / 100 - loss: 1.5378 - accuracy: 64.43%\n",
            "Epoch 20 / 100 - loss: 1.5055 - accuracy: 64.90%\n",
            "Epoch 21 / 100 - loss: 1.4748 - accuracy: 65.36%\n",
            "Epoch 22 / 100 - loss: 1.4458 - accuracy: 65.83%\n",
            "Epoch 23 / 100 - loss: 1.4177 - accuracy: 66.24%\n",
            "Epoch 24 / 100 - loss: 1.3931 - accuracy: 66.60%\n",
            "Epoch 25 / 100 - loss: 1.3689 - accuracy: 67.00%\n",
            "Epoch 26 / 100 - loss: 1.3452 - accuracy: 67.37%\n",
            "Epoch 27 / 100 - loss: 1.3238 - accuracy: 67.69%\n",
            "Epoch 28 / 100 - loss: 1.3023 - accuracy: 68.05%\n",
            "Epoch 29 / 100 - loss: 1.2822 - accuracy: 68.36%\n",
            "Epoch 30 / 100 - loss: 1.2630 - accuracy: 68.68%\n",
            "Epoch 31 / 100 - loss: 1.2450 - accuracy: 68.98%\n",
            "Epoch 32 / 100 - loss: 1.2276 - accuracy: 69.28%\n",
            "Epoch 33 / 100 - loss: 1.2110 - accuracy: 69.52%\n",
            "Epoch 34 / 100 - loss: 1.1939 - accuracy: 69.83%\n",
            "Epoch 35 / 100 - loss: 1.1791 - accuracy: 70.08%\n",
            "Epoch 36 / 100 - loss: 1.1640 - accuracy: 70.34%\n",
            "Epoch 37 / 100 - loss: 1.1491 - accuracy: 70.59%\n",
            "Epoch 38 / 100 - loss: 1.1349 - accuracy: 70.86%\n",
            "Epoch 39 / 100 - loss: 1.1228 - accuracy: 71.04%\n",
            "Epoch 40 / 100 - loss: 1.1086 - accuracy: 71.29%\n",
            "Epoch 41 / 100 - loss: 1.0967 - accuracy: 71.51%\n",
            "Epoch 42 / 100 - loss: 1.0844 - accuracy: 71.70%\n",
            "Epoch 43 / 100 - loss: 1.0726 - accuracy: 71.92%\n",
            "Epoch 44 / 100 - loss: 1.0608 - accuracy: 72.15%\n",
            "Epoch 45 / 100 - loss: 1.0507 - accuracy: 72.31%\n",
            "Epoch 46 / 100 - loss: 1.0389 - accuracy: 72.54%\n",
            "Epoch 47 / 100 - loss: 1.0288 - accuracy: 72.72%\n",
            "Epoch 48 / 100 - loss: 1.0189 - accuracy: 72.89%\n",
            "Epoch 49 / 100 - loss: 1.0085 - accuracy: 73.09%\n",
            "Epoch 50 / 100 - loss: 0.9989 - accuracy: 73.27%\n",
            "Epoch 51 / 100 - loss: 0.9898 - accuracy: 73.45%\n",
            "Epoch 52 / 100 - loss: 0.9804 - accuracy: 73.62%\n",
            "Epoch 53 / 100 - loss: 0.9722 - accuracy: 73.77%\n",
            "Epoch 54 / 100 - loss: 0.9638 - accuracy: 73.93%\n",
            "Epoch 55 / 100 - loss: 0.9546 - accuracy: 74.09%\n",
            "Epoch 56 / 100 - loss: 0.9459 - accuracy: 74.28%\n",
            "Epoch 57 / 100 - loss: 0.9394 - accuracy: 74.42%\n",
            "Epoch 58 / 100 - loss: 0.9309 - accuracy: 74.58%\n",
            "Epoch 59 / 100 - loss: 0.9221 - accuracy: 74.75%\n",
            "Epoch 60 / 100 - loss: 0.9153 - accuracy: 74.88%\n",
            "Epoch 61 / 100 - loss: 0.9087 - accuracy: 75.03%\n",
            "Epoch 62 / 100 - loss: 0.9010 - accuracy: 75.14%\n",
            "Epoch 63 / 100 - loss: 0.8946 - accuracy: 75.26%\n",
            "Epoch 64 / 100 - loss: 0.8875 - accuracy: 75.42%\n",
            "Epoch 65 / 100 - loss: 0.8800 - accuracy: 75.56%\n",
            "Epoch 66 / 100 - loss: 0.8737 - accuracy: 75.71%\n",
            "Epoch 67 / 100 - loss: 0.8678 - accuracy: 75.82%\n",
            "Epoch 68 / 100 - loss: 0.8614 - accuracy: 75.96%\n",
            "Epoch 69 / 100 - loss: 0.8557 - accuracy: 76.06%\n",
            "Epoch 70 / 100 - loss: 0.8494 - accuracy: 76.19%\n",
            "Epoch 71 / 100 - loss: 0.8436 - accuracy: 76.31%\n",
            "Epoch 72 / 100 - loss: 0.8375 - accuracy: 76.44%\n",
            "Epoch 73 / 100 - loss: 0.8319 - accuracy: 76.57%\n",
            "Epoch 74 / 100 - loss: 0.8249 - accuracy: 76.69%\n",
            "Epoch 75 / 100 - loss: 0.8202 - accuracy: 76.79%\n",
            "Epoch 76 / 100 - loss: 0.8154 - accuracy: 76.91%\n",
            "Epoch 77 / 100 - loss: 0.8101 - accuracy: 77.00%\n",
            "Epoch 78 / 100 - loss: 0.8048 - accuracy: 77.12%\n",
            "Epoch 79 / 100 - loss: 0.7995 - accuracy: 77.24%\n",
            "Epoch 80 / 100 - loss: 0.7950 - accuracy: 77.33%\n",
            "Epoch 81 / 100 - loss: 0.7899 - accuracy: 77.43%\n",
            "Epoch 82 / 100 - loss: 0.7847 - accuracy: 77.55%\n",
            "Epoch 83 / 100 - loss: 0.7800 - accuracy: 77.61%\n",
            "Epoch 84 / 100 - loss: 0.7746 - accuracy: 77.78%\n",
            "Epoch 85 / 100 - loss: 0.7697 - accuracy: 77.88%\n",
            "Epoch 86 / 100 - loss: 0.7660 - accuracy: 77.94%\n",
            "Epoch 87 / 100 - loss: 0.7609 - accuracy: 78.06%\n",
            "Epoch 88 / 100 - loss: 0.7566 - accuracy: 78.15%\n",
            "Epoch 89 / 100 - loss: 0.7517 - accuracy: 78.26%\n",
            "Epoch 90 / 100 - loss: 0.7479 - accuracy: 78.35%\n",
            "Epoch 91 / 100 - loss: 0.7448 - accuracy: 78.42%\n",
            "Epoch 92 / 100 - loss: 0.7399 - accuracy: 78.53%\n",
            "Epoch 93 / 100 - loss: 0.7355 - accuracy: 78.61%\n",
            "Epoch 94 / 100 - loss: 0.7313 - accuracy: 78.72%\n",
            "Epoch 95 / 100 - loss: 0.7280 - accuracy: 78.80%\n",
            "Epoch 96 / 100 - loss: 0.7236 - accuracy: 78.89%\n",
            "Epoch 97 / 100 - loss: 0.7198 - accuracy: 78.97%\n",
            "Epoch 98 / 100 - loss: 0.7155 - accuracy: 79.06%\n",
            "Epoch 99 / 100 - loss: 0.7118 - accuracy: 79.15%\n",
            "Epoch 100 / 100 - loss: 0.7080 - accuracy: 79.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def en_token_rejoin(tokens):\n",
        "  sentence = \"\"\n",
        "  for token in tokens:\n",
        "    if token[0] in [\"'\", \".\", \",\", \"!\", \"?\", \":\", \";\"]:\n",
        "      sentence = sentence.rstrip() + token\n",
        "      continue\n",
        "\n",
        "    sentence+= token + \" \"\n",
        "\n",
        "  return sentence\n",
        "\n",
        "def translate_sentence(model, sentence, max_length=MAX_SENT_LEN):\n",
        "  if type(sentence) == str:\n",
        "      tokens = [token.text.lower() for token in spacy_fr(sentence)]\n",
        "\n",
        "  else:\n",
        "      tokens = [token.lower() for token in sentence]\n",
        "\n",
        "  tokens.insert(0, START_TOKEN)\n",
        "  tokens.append(END_TOKEN)\n",
        "\n",
        "  unknown_tokens = {}\n",
        "  for idx, token in enumerate(tokens):\n",
        "    if token not in fr_tok2idx:\n",
        "      unknown_tokens[idx] = token\n",
        "      tokens.remove(token)\n",
        "\n",
        "  text_to_indices = [fr_tok2idx[token] for token in tokens]\n",
        "  sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "  outputs = [en_tok2idx[START_TOKEN]]\n",
        "  for i in range(max_length):\n",
        "      trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output = model(sentence_tensor, trg_tensor)\n",
        "\n",
        "      best_guess = output.argmax(2)[-1, :].item()\n",
        "      if best_guess == en_tok2idx[END_TOKEN]:\n",
        "          break\n",
        "\n",
        "      outputs.append(best_guess)\n",
        "\n",
        "  translated_sentence = [en_idx2tok[idx] for idx in outputs]\n",
        "  for idx, token in unknown_tokens.items():\n",
        "    translated_sentence.insert(idx, token)\n",
        "\n",
        "  return en_token_rejoin(translated_sentence[1:])\n",
        "\n",
        "def batch_translate_tensor(model, batch_data, max_length=MAX_SEQ_LEN):\n",
        "  data_len, seq_len = batch_data.shape\n",
        "\n",
        "  src = batch_data.T.to(device)\n",
        "  trg = torch.full(\n",
        "      (1, data_len),\n",
        "      en_tok2idx[START_TOKEN],\n",
        "      dtype=torch.long,\n",
        "      device=device\n",
        "  )\n",
        "\n",
        "  finished = torch.zeros(data_len, dtype=torch.bool, device=device)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    with torch.no_grad():\n",
        "      output = model(src, trg)\n",
        "\n",
        "    next_token_logits = output[-1, :, :]\n",
        "    next_tokens = next_token_logits.argmax(dim=1)\n",
        "\n",
        "    next_tokens = next_tokens.masked_fill(finished, fr_tok2idx[END_TOKEN])\n",
        "    trg = torch.cat([trg, next_tokens.unsqueeze(0)], dim=0)\n",
        "\n",
        "    finished |= (next_tokens == fr_tok2idx[END_TOKEN])\n",
        "    if finished.all():\n",
        "      break\n",
        "\n",
        "  translations = []\n",
        "  trg_np = trg.detach().cpu().numpy().T\n",
        "\n",
        "  for seq in trg_np:\n",
        "    words = []\n",
        "    for idx in seq[1:]:\n",
        "      if idx == en_tok2idx[END_TOKEN]:\n",
        "        break\n",
        "      words.append(en_idx2tok[idx])\n",
        "    translations.append(\" \".join(words))\n",
        "\n",
        "  return translations\n",
        "\n",
        "def bleu_score(model, test_iter, max_count=None):\n",
        "  trgs = []\n",
        "  pred_trgs = []\n",
        "  cnt = 0\n",
        "\n",
        "  for (x, y) in test_iter:\n",
        "    src = x.to(device)\n",
        "    trg = y[:, :-1]\n",
        "\n",
        "    pred = batch_translate_tensor(model, src)\n",
        "    pred_trgs.extend(pred)\n",
        "    for sent_tok in trg:\n",
        "      trgs.append([\" \".join([ val for tok in sent_tok if (val:=en_idx2tok[tok.item()]) not in [START_TOKEN, END_TOKEN, PAD_TOKEN]])])\n",
        "\n",
        "    cnt += src.shape[0]\n",
        "    if max_count and cnt >= max_count:\n",
        "      break\n",
        "\n",
        "  bleu = BLEUScore().to(device)\n",
        "  score = bleu(pred_trgs, trgs)\n",
        "\n",
        "  print(f\"Total tested datapoints: {cnt}\")\n",
        "  print(f\"BLEU score: {score * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "aGvP5oDgZnm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sent = \"je suis en train de\"\n",
        "actual_translation = \"I am in the process of\"\n",
        "model.eval()\n",
        "prediction = translate_sentence(model, input_sent)\n",
        "print(f\"Input sentence: {input_sent}\")\n",
        "print(f\"Translated sentence: {prediction}\")\n",
        "print(f\"Actual translation: {actual_translation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-XQ61gotSS4",
        "outputId": "a40af62b-e5f9-43e0-f1d2-91bf2a480597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence: je suis en train de\n",
            "Translated sentence: i am in the process of it.\n",
            "Actual translation: I am in the process of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "bleu_score(model, test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KbjwCRWuFg4",
        "outputId": "005e5e07-560c-4ff8-9f09-867feb528dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tested datapoints: 19868\n",
            "BLEU score: 55.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wim-PkS1SFj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}