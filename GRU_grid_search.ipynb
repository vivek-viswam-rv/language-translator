{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivek-viswam-rv/language-translator/blob/main/GRU_grid_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "bslUSP_A5zxH"
      },
      "id": "bslUSP_A5zxH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d785a3a7",
      "metadata": {
        "id": "d785a3a7"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "# downloading the europarl fr-en dataset\n",
        "url = \"http://www.statmt.org/europarl/v7/fr-en.tgz\"\n",
        "filename = \"fr-en.tgz\"\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "with tarfile.open(filename, \"r:gz\") as tar:\n",
        "    tar.extractall(\"europarl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "58MDoNEBqN_9"
      },
      "id": "58MDoNEBqN_9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c98c758",
      "metadata": {
        "id": "3c98c758"
      },
      "outputs": [],
      "source": [
        "ENGLISH_PATH = \"europarl/europarl-v7.fr-en.en\"\n",
        "FRENCH_PATH = \"europarl/europarl-v7.fr-en.fr\"\n",
        "\n",
        "def zip_files(english_path, french_path):\n",
        "    with open(english_path, \"r\", encoding=\"utf-8\") as f_english, \\\n",
        "         open(french_path, \"r\", encoding=\"utf-8\") as f_french:\n",
        "        french_lines = f_french.readlines()\n",
        "        english_lines = f_english.readlines()\n",
        "\n",
        "    assert len(english_lines) == len(french_lines), \"different number of lines in files!!\"\n",
        "    pairs = list(zip(french_lines, english_lines))\n",
        "    return pairs\n",
        "\n",
        "sentence_pairs = zip_files(ENGLISH_PATH, FRENCH_PATH)\n",
        "\n",
        "print(\"total sentence pairs:\", len(sentence_pairs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77940f0",
      "metadata": {
        "id": "a77940f0"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def clean_text(s: str) -> str:\n",
        "    # normalize unicode to NFC\n",
        "    s = unicodedata.normalize(\"NFC\", s)\n",
        "    # replace non breaking space with regular space\n",
        "    s = s.replace(\"\\xa0\", \" \")\n",
        "    # collapse multiple spaces into a single space\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    # strip whitespace and lowercase all letters\n",
        "    return s.strip().lower()\n",
        "\n",
        "def clean_data(sentences):\n",
        "    cleaned_data = []\n",
        "    for french, english in sentences:\n",
        "        french_clean = clean_text(french)\n",
        "        english_clean = clean_text(english)\n",
        "        if french_clean == \"\" or english_clean == \"\":\n",
        "            continue\n",
        "        cleaned_data.append((french_clean, english_clean))\n",
        "    return cleaned_data\n",
        "\n",
        "\n",
        "cleaned_data = clean_data(sentence_pairs)\n",
        "print(\"after cleaning total sentence pairs:\", len(cleaned_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c220aabf",
      "metadata": {
        "id": "c220aabf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(cleaned_data)\n",
        "\n",
        "n_total = len(cleaned_data)\n",
        "n_train = int(0.80 * n_total)\n",
        "n_validation = int(0.10 * n_total)\n",
        "n_test = n_total - n_train - n_validation\n",
        "\n",
        "train_pairs      = cleaned_data[:n_train]\n",
        "validation_pairs = cleaned_data[n_train:n_train+n_validation]\n",
        "test_pairs       = cleaned_data[n_train+n_validation:]\n",
        "\n",
        "train_pairs = train_pairs[:20000]\n",
        "validation_pairs = validation_pairs[:10000]\n",
        "test_pairs = test_pairs[:10000]\n",
        "\n",
        "with open(\"fr_train.txt\", \"w\", encoding=\"utf-8\") as f_fr, \\\n",
        "     open(\"en_train.txt\", \"w\", encoding=\"utf-8\") as f_en:\n",
        "    for fr, en in train_pairs:\n",
        "        f_fr.write(fr + \"\\n\")\n",
        "        f_en.write(en + \"\\n\")\n",
        "\n",
        "\n",
        "print(f\"train: {len(train_pairs)}, val: {len(validation_pairs)}, test: {len(test_pairs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#french\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=\"fr_train.txt\",\n",
        "    model_prefix=\"sp_fr\",\n",
        "    vocab_size=10000,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=0.9995,\n",
        "    pad_id=0,\n",
        "    unk_id=1,\n",
        "    bos_id=2,\n",
        "    eos_id=3,\n",
        "    num_threads=1,\n",
        "    shuffle_input_sentence=False,\n",
        "    input_sentence_size=0,\n",
        "    seed_sentencepiece_size=0\n",
        ")\n",
        "\n",
        "#english\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=\"en_train.txt\",\n",
        "    model_prefix=\"sp_en\",\n",
        "    vocab_size=10000,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=0.9995,\n",
        "    pad_id=0,\n",
        "    unk_id=1,\n",
        "    bos_id=2,\n",
        "    eos_id=3,\n",
        "    num_threads=1,\n",
        "    shuffle_input_sentence=False,\n",
        "    input_sentence_size=0,\n",
        "    seed_sentencepiece_size=0\n",
        ")\n",
        "\n",
        "sp_fr = spm.SentencePieceProcessor()\n",
        "sp_fr.load(\"sp_fr.model\")\n",
        "\n",
        "sp_en = spm.SentencePieceProcessor()\n",
        "sp_en.load(\"sp_en.model\")\n",
        "\n",
        "# vocab sizes\n",
        "source_vocab_size = sp_fr.get_piece_size()\n",
        "target_vocab_size = sp_en.get_piece_size()\n",
        "\n",
        "SOURCE_PAD_IDX = sp_fr.pad_id()\n",
        "SOURCE_UNK_IDX = sp_fr.unk_id()\n",
        "SOURCE_BOS_IDX = sp_fr.bos_id()\n",
        "SOURCE_EOS_IDX = sp_fr.eos_id()\n",
        "\n",
        "TARGET_PAD_IDX = sp_en.pad_id()\n",
        "TARGET_UNK_IDX = sp_en.unk_id()\n",
        "TARGET_BOS_IDX = sp_en.bos_id()\n",
        "TARGET_EOS_IDX = sp_en.eos_id()\n"
      ],
      "metadata": {
        "id": "J1Xb09TpqgmQ"
      },
      "id": "J1Xb09TpqgmQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy(\"sp_fr.model\", \"/content/drive/MyDrive/sp_fr.model\")\n",
        "shutil.copy(\"sp_fr.vocab\", \"/content/drive/MyDrive/sp_fr.vocab\")\n",
        "\n",
        "shutil.copy(\"sp_en.model\", \"/content/drive/MyDrive/sp_en.model\")\n",
        "shutil.copy(\"sp_en.vocab\", \"/content/drive/MyDrive/sp_en.vocab\")\n"
      ],
      "metadata": {
        "id": "p0tg7mYD6EYU"
      },
      "id": "p0tg7mYD6EYU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14b1b5a",
      "metadata": {
        "id": "a14b1b5a"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "#max subword length is 60\n",
        "MAX_LEN = 60\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, pairs, sp_source, sp_target, max_len=MAX_LEN):\n",
        "        self.pairs = pairs\n",
        "        self.sp_source = sp_source\n",
        "        self.sp_target = sp_target\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        french_str, english_str = self.pairs[idx]\n",
        "        src_ids = self.sp_source.encode(french_str, out_type=int)[:max_len]\n",
        "        toks = self.sp_target.encode(english_str, out_type=int)[:self.max_len-2]\n",
        "        tgt_ids = [TARGET_BOS_IDX] + toks + [TARGET_EOS_IDX]\n",
        "        src_ids = src_ids[:self.max_len]\n",
        "        tgt_ids = tgt_ids[:self.max_len]\n",
        "\n",
        "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_seqs, tgt_seqs = zip(*batch)\n",
        "    src_lengths = torch.tensor([len(s) for s in src_seqs], dtype=torch.long)\n",
        "    tgt_lengths = torch.tensor([len(t) for t in tgt_seqs], dtype=torch.long)\n",
        "    src_padded = pad_sequence(src_seqs, batch_first=True, padding_value=SOURCE_PAD_IDX)\n",
        "    tgt_padded = pad_sequence(tgt_seqs, batch_first=True, padding_value=TARGET_PAD_IDX)\n",
        "\n",
        "    return src_padded, tgt_padded, src_lengths, tgt_lengths\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c99237",
      "metadata": {
        "id": "c2c99237"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = TranslationDataset(train_pairs,      sp_fr, sp_en)\n",
        "val_dataset   = TranslationDataset(validation_pairs, sp_fr, sp_en)\n",
        "test_dataset  = TranslationDataset(test_pairs,       sp_fr, sp_en)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "validation_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                               shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                         shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "source_batch, target_batch, source_lengths, target_lengths = next(iter(train_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f41ad6",
      "metadata": {
        "id": "d9f41ad6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "        # input_dim is the size of french vocab\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=SOURCE_PAD_IDX)\n",
        "        self.gru = nn.GRU(\n",
        "            embed_dim,\n",
        "            hidden_dim,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, source):\n",
        "        #we start by embedding the input tokens\n",
        "        embedded = self.dropout(self.embedding(source))\n",
        "\n",
        "        #we pass the embedded tokens through the bidirectional GRU\n",
        "        encoder_outputs, hidden = self.gru(embedded)\n",
        "        forward_hidden  = hidden[-2]\n",
        "        backward_hidden = hidden[-1]\n",
        "\n",
        "        #concatenate & map to decoder hidden size\n",
        "        combined_hidden = torch.cat((forward_hidden, backward_hidden), dim=1)\n",
        "        decoder_init_hidden = torch.tanh(self.fc(combined_hidden)).unsqueeze(0)\n",
        "\n",
        "        return encoder_outputs, decoder_init_hidden\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Linear(encoder_hidden_dim * 2 + decoder_hidden_dim, decoder_hidden_dim)\n",
        "        self.v = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs, source_mask):\n",
        "        source_length = encoder_outputs.size(1)\n",
        "        decoder_hidden = decoder_hidden.permute(1, 0, 2).repeat(1, source_length, 1)\n",
        "        combined = torch.cat((decoder_hidden, encoder_outputs), dim=2)\n",
        "        energy = torch.tanh(self.attention(combined))\n",
        "        scores = self.v(energy).squeeze(-1)\n",
        "        scores = scores.masked_fill(~source_mask, -1e9)\n",
        "        attention_weights = F.softmax(scores, dim=1)\n",
        "\n",
        "        return attention_weights\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, embed_dim, encoder_hidden_dim, decoder_hidden_dim, attention, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, embed_dim, padding_idx=TARGET_PAD_IDX)\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            embed_dim + encoder_hidden_dim * 2,\n",
        "            decoder_hidden_dim,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(\n",
        "            decoder_hidden_dim + encoder_hidden_dim * 2 + embed_dim,\n",
        "            output_dim,\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_token, hidden, encoder_outputs, source_mask):\n",
        "        input_token = input_token.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input_token))\n",
        "\n",
        "        attention_weights = self.attention(hidden, encoder_outputs, source_mask).unsqueeze(1)\n",
        "        context = attention_weights @ encoder_outputs\n",
        "        gru_input = torch.cat((embedded, context), dim=2)\n",
        "        output, hidden = self.gru(gru_input, hidden)\n",
        "        output = output.squeeze(1)\n",
        "        context = context.squeeze(1)\n",
        "        embedded = embedded.squeeze(1)\n",
        "\n",
        "        combined = torch.cat((output, context, embedded), dim=1)\n",
        "        logits = self.fc_out(combined)\n",
        "\n",
        "        return logits, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.size(0)\n",
        "        target_length = target.size(1)\n",
        "        output_dim = self.decoder.output_dim\n",
        "        outputs = torch.zeros(batch_size, target_length - 1, output_dim, device=self.device)\n",
        "        encoder_outputs, hidden = self.encoder(source)\n",
        "        source_mask = (source != SOURCE_PAD_IDX).bool()\n",
        "        input_token = target[:, 0]\n",
        "\n",
        "        for t in range(1, target_length):\n",
        "            logits, hidden = self.decoder(\n",
        "                input_token,\n",
        "                hidden,\n",
        "                encoder_outputs,\n",
        "                source_mask,\n",
        "            )\n",
        "\n",
        "            outputs[:, t - 1, :] = logits\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top_prediction = logits.argmax(dim=1)\n",
        "            input_token = target[:, t] if teacher_force else top_prediction\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78a473e",
      "metadata": {
        "id": "c78a473e"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, teacher_forcing_ratio=0.5):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for source_batch, target_batch, source_lengths, target_lengths in dataloader:\n",
        "        source_batch = source_batch.to(device)\n",
        "        target_batch = target_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(source_batch, target_batch, teacher_forcing_ratio=teacher_forcing_ratio)\n",
        "        targ = target_batch[:, 1:]\n",
        "        logits = outputs.reshape(-1, outputs.size(-1))\n",
        "        targ = targ.reshape(-1)\n",
        "        loss = criterion(logits, targ)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for source_batch, target_batch, source_lengths, target_lengths in dataloader:\n",
        "        source_batch = source_batch.to(device)\n",
        "        target_batch = target_batch.to(device)\n",
        "        outputs = model(source_batch, target_batch, teacher_forcing_ratio=0.0)\n",
        "        targ = target_batch[:, 1:]\n",
        "        logits = outputs.reshape(-1, outputs.size(-1))\n",
        "        targ = targ.reshape(-1)\n",
        "        loss = criterion(logits, targ)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "N_EPOCHS = 50\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, teacher_forcing_ratio=max(0.3, 1 - epoch * 0.03))\n",
        "    val_loss = evaluate(model, validation_loader, criterion)\n",
        "    training_losses.append(train_loss)\n",
        "    validation_losses.append(val_loss)\n",
        "    if val_loss < min(validation_losses):\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_checkpoint = {\n",
        "    \"state_dict\": model.state_dict(),\n",
        "    \"config\": {\n",
        "        \"HIDDEN_DIM\":        512,\n",
        "        \"ENCODER_EMBED_DIM\": 256,\n",
        "        \"DECODER_EMBED_DIM\": 256,\n",
        "        \"DROPOUT\":           0.2,\n",
        "        \"LR\":                1e-3,\n",
        "    },\n",
        "    \"tokenizers\": {\n",
        "        \"sp_fr_model\": \"/content/drive/MyDrive/sp_fr.model\",\n",
        "        \"sp_en_model\": \"/content/drive/MyDrive/sp_en.model\",\n",
        "    },\n",
        "}\n",
        "\n",
        "torch.save(best_checkpoint, \"/content/drive/MyDrive/europarl_gru_best.pt\")\n"
      ],
      "metadata": {
        "id": "k-WqdyWv68El"
      },
      "id": "k-WqdyWv68El",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "@torch.no_grad()\n",
        "def translate_sentence_greedy(\n",
        "    model,\n",
        "    fr_str,\n",
        "    sp_source,\n",
        "    sp_target,\n",
        "    max_len=60,\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    fr_str = clean_text(fr_str)\n",
        "\n",
        "    src_ids = sp_source.encode(fr_str, out_type=int)[:max_len]\n",
        "    src_tensor = torch.tensor(src_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "    source_mask = (src_tensor != SOURCE_PAD_IDX).bool()\n",
        "    input_token = torch.tensor([TARGET_BOS_IDX], device=device)\n",
        "    decoded_ids = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        logits, hidden = model.decoder(input_token, hidden, encoder_outputs, source_mask)\n",
        "        next_token = logits.argmax(dim=-1)\n",
        "        next_id = next_token.item()\n",
        "\n",
        "        if next_id == TARGET_EOS_IDX:\n",
        "            break\n",
        "\n",
        "        decoded_ids.append(next_id)\n",
        "        input_token = next_token\n",
        "    return sp_target.decode(decoded_ids)\n"
      ],
      "metadata": {
        "id": "aPefsdW9abvK"
      },
      "id": "aPefsdW9abvK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu\n",
        "import sacrebleu\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_bleu(\n",
        "    model,\n",
        "    test_pairs,\n",
        "    sp_source,\n",
        "    sp_target,\n",
        "    max_len=60,\n",
        "    num_samples=10000,\n",
        "    decode_fn=translate_sentence_greedy,\n",
        "):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    refs = []\n",
        "\n",
        "    pairs = test_pairs[:num_samples]\n",
        "\n",
        "    for fr, en_targ in pairs:\n",
        "        pred_en = decode_fn(model, fr, sp_source, sp_target, max_len=max_len)\n",
        "\n",
        "        preds.append(pred_en.strip())\n",
        "        refs.append(en_targ.strip())\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(preds, [refs])\n",
        "    print(f\"BLEU score: {bleu.score:.2f}\")\n",
        "    return bleu.score\n"
      ],
      "metadata": {
        "id": "3eX13vfhcjFQ"
      },
      "id": "3eX13vfhcjFQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/best_gru_model.pt\"\n",
        "model = torch.load(PATH, map_location=device, weights_only=False)\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "HVHTM-2IKNBw"
      },
      "id": "HVHTM-2IKNBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=TARGET_PAD_IDX)\n",
        "val_loss = evaluate(model, validation_loader, criterion)\n",
        "print(\"validation loss of loaded model:\", val_loss)\n"
      ],
      "metadata": {
        "id": "omeT5RN_4FBw"
      },
      "id": "omeT5RN_4FBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "os.makedirs(\"plots\", exist_ok=True)\n",
        "\n",
        "def build_model_and_optimizer(cfg):\n",
        "    encoder = Encoder(\n",
        "        input_dim=source_vocab_size,\n",
        "        embed_dim=cfg[\"ENCODER_EMBED_DIM\"],\n",
        "        hidden_dim=cfg[\"HIDDEN_DIM\"],\n",
        "        dropout=cfg[\"DROPOUT\"],\n",
        "    ).to(device)\n",
        "\n",
        "    attention = BahdanauAttention(\n",
        "        encoder_hidden_dim=cfg[\"HIDDEN_DIM\"],\n",
        "        decoder_hidden_dim=cfg[\"HIDDEN_DIM\"],\n",
        "    ).to(device)\n",
        "\n",
        "    decoder = Decoder(\n",
        "        output_dim=target_vocab_size,\n",
        "        embed_dim=cfg[\"DECODER_EMBED_DIM\"],\n",
        "        encoder_hidden_dim=cfg[\"HIDDEN_DIM\"],\n",
        "        decoder_hidden_dim=cfg[\"HIDDEN_DIM\"],\n",
        "        attention=attention,\n",
        "        dropout=cfg[\"DROPOUT\"],\n",
        "    ).to(device)\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"LR\"])\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=TARGET_PAD_IDX)\n",
        "\n",
        "    return model, optimizer, criterion\n",
        "\n",
        "\n",
        "def run_experiment(cfg, num_epochs=15, teacher_forcing_start=1.0):\n",
        "    print(f\"\\nrunning config: {cfg}\")\n",
        "\n",
        "    model, optimizer, criterion = build_model_and_optimizer(cfg)\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_state = None\n",
        "    train_hist = []\n",
        "    val_hist   = []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        tf_ratio = max(0.3, teacher_forcing_start - 0.05 * (epoch - 1))\n",
        "        train_loss = train_one_epoch(\n",
        "            model,\n",
        "            train_loader,\n",
        "            optimizer,\n",
        "            criterion,\n",
        "            teacher_forcing_ratio=tf_ratio,\n",
        "        )\n",
        "        val_loss = evaluate(model, validation_loader, criterion)\n",
        "        train_hist.append(train_loss)\n",
        "        val_hist.append(val_loss)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_state = deepcopy(model.state_dict())\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d}: \"\n",
        "            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, TF={tf_ratio:.2f}\"\n",
        "        )\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    cfg_tag = (\n",
        "        f\"hd{cfg['HIDDEN_DIM']}_\"\n",
        "        f\"emb{cfg['ENCODER_EMBED_DIM']}_\"\n",
        "        f\"lr{str(cfg['LR']).replace('.', 'p')}_\"\n",
        "        f\"do{str(cfg['DROPOUT']).replace('.', 'p')}\"\n",
        "    )\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(train_hist, label=\"train\")\n",
        "    plt.plot(val_hist,   label=\"val\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"GRU Loss curves ({cfg_tag})\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"gru_plots/gru_loss_{cfg_tag}.png\", dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "            \"config\": cfg,\n",
        "            \"train_loss\": train_hist,\n",
        "            \"val_loss\": val_hist,\n",
        "            \"best_val_loss\": best_val_loss,\n",
        "        },\n",
        "        f\"plots/gru_loss_{cfg_tag}.pt\",\n",
        "    )\n",
        "    val_bleu = compute_bleu(\n",
        "        model,\n",
        "        validation_pairs,\n",
        "        sp_fr,\n",
        "        sp_en,\n",
        "        max_len=MAX_LEN,\n",
        "        num_samples=1000,\n",
        "        decode_fn=translate_sentence_greedy,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"config {cfg} -> best_val_loss={best_val_loss:.4f}, \"\n",
        "        f\"val_bleu={val_bleu:.2f}\"\n",
        "    )\n",
        "\n",
        "    return best_val_loss, val_bleu\n"
      ],
      "metadata": {
        "id": "yeAyjT0Eic6n"
      },
      "id": "yeAyjT0Eic6n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "n8vjAH-Q02Wh"
      },
      "id": "n8vjAH-Q02Wh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "search_space = {\n",
        "    \"HIDDEN_DIM\":        [256, 512],\n",
        "    \"ENCODER_EMBED_DIM\": [256, 512],\n",
        "    \"DECODER_EMBED_DIM\": [256, 512],\n",
        "    \"DROPOUT\":   [0.1, 0.3],\n",
        "    \"LR\":                [1e-3, 5e-4],\n",
        "}\n",
        "\n",
        "configs = []\n",
        "keys = list(search_space.keys())\n",
        "for values in product(*search_space.values()):\n",
        "    cfg = dict(zip(keys, values))\n",
        "    configs.append(cfg)\n",
        "results = []\n",
        "for cfg in configs:\n",
        "    val_loss, val_bleu = run_experiment(cfg, num_epochs=20)\n",
        "    results.append({**cfg, \"val_loss\": val_loss, \"val_bleu\": val_bleu})\n",
        "\n",
        "results_sorted = sorted(results, key=lambda r: r[\"val_bleu\"], reverse=True)\n",
        "print(\"\\ngrid search results\")\n",
        "for r in results_sorted:\n",
        "    print(r)\n"
      ],
      "metadata": {
        "id": "8yAnS7C9KVdS"
      },
      "id": "8yAnS7C9KVdS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}